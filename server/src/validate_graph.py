#!/usr/bin/env python3
"""
Graph Quality Validation Script

Evaluates the quality of knowledge graphs generated by Graphiti
and determines if the chunking strategy is appropriate.
"""

import argparse
import asyncio
import json
from typing import Any

from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client


async def get_graph_statistics(session: ClientSession) -> dict[str, Any]:
    stats = {}

    episodes_result = await session.call_tool(
        "get_episodes", arguments={"max_episodes": 1000, "group_ids": ["main"]}
    )
    episodes_data = episodes_result.structuredContent or json.loads(
        episodes_result.content[0].text
    )
    episodes = (
        episodes_data.get("result", {}).get("episodes", [])
        if isinstance(episodes_data, dict) and "result" in episodes_data
        else episodes_data.get("episodes", [])
    )
    stats["episode_count"] = len(episodes)

    if episodes:
        episode_lengths = [len(ep["content"]) for ep in episodes]
        stats["avg_episode_length"] = sum(episode_lengths) / len(episode_lengths)
        stats["min_episode_length"] = min(episode_lengths)
        stats["max_episode_length"] = max(episode_lengths)

    nodes_result = await session.call_tool(
        "search_nodes",
        arguments={
            "query": "GraphRAG OR Slack OR tonoyama OR entity",
            "max_nodes": 1000,
            "group_ids": ["main"],
        },
    )
    nodes_data = (
        nodes_result.structuredContent["result"]
        if nodes_result.structuredContent
        else json.loads(nodes_result.content[0].text)
    )
    nodes = nodes_data.get("nodes", [])
    stats["node_count"] = len(nodes)

    if nodes:
        node_labels = {}
        for node in nodes:
            for label in node.get("labels", []):
                node_labels[label] = node_labels.get(label, 0) + 1
        stats["node_labels"] = node_labels

        summary_lengths = [
            len(node.get("summary", "")) for node in nodes if node.get("summary")
        ]
        if summary_lengths:
            stats["avg_node_summary_length"] = sum(summary_lengths) / len(
                summary_lengths
            )

    facts_result = await session.call_tool(
        "search_memory_facts",
        arguments={
            "query": "GraphRAG OR Slack OR entity",
            "max_facts": 1000,
            "group_ids": ["main"],
        },
    )
    facts_data = (
        facts_result.structuredContent["result"]
        if facts_result.structuredContent
        else json.loads(facts_result.content[0].text)
    )
    facts = facts_data.get("facts", [])
    stats["fact_count"] = len(facts)

    if facts:
        fact_types = {}
        for fact in facts:
            fact_name = fact.get("name", "UNKNOWN")
            fact_types[fact_name] = fact_types.get(fact_name, 0) + 1
        stats["fact_types"] = fact_types

    return stats


def _evaluate_node_episode_ratio(
    episode_count: int, node_count: int, details: list[str]
) -> int:
    """Evaluate node/episode ratio and return score."""
    if episode_count == 0:
        return 0

    if node_count == 0:
        details.append("‚ùå No nodes generated")
        return 0

    ratio = node_count / episode_count
    if 0.3 <= ratio <= 3.0:
        details.append(f"‚úÖ Node/Episode ratio: {ratio:.2f} (appropriate: 0.3-3.0)")
        return 10

    details.append(f"‚ö†Ô∏è  Node/Episode ratio: {ratio:.2f} (recommended: 0.3-3.0)")
    return 5


def _evaluate_fact_node_ratio(
    fact_count: int, node_count: int, details: list[str]
) -> int:
    """Evaluate fact/node ratio and return score."""
    if fact_count == 0:
        details.append("‚ùå No facts (relationships) exist")
        return 0

    if node_count == 0:
        details.append("‚ùå No facts generated")
        return 0

    ratio = fact_count / node_count
    if ratio >= 1.0:
        details.append(f"‚úÖ Fact/Node ratio: {ratio:.2f} (good: >= 1.0)")
        return 10

    if ratio >= 0.5:
        details.append(f"‚ö†Ô∏è  Fact/Node ratio: {ratio:.2f} (improvable: 0.5-1.0)")
        return 7

    details.append(f"‚ùå Fact/Node ratio: {ratio:.2f} (too low: < 0.5)")
    return 3


def _evaluate_episode_length(avg_episode_length: float, details: list[str]) -> int:
    """Evaluate average episode length and return score."""
    if avg_episode_length == 0:
        return 0

    if 200 <= avg_episode_length <= 2000:
        details.append(
            f"‚úÖ Average episode length: {avg_episode_length:.0f} chars (appropriate: 200-2000)"
        )
        return 10

    if 100 <= avg_episode_length < 200:
        details.append(
            f"‚ö†Ô∏è  Average episode length: {avg_episode_length:.0f} chars (short: 100-200)"
        )
        return 7

    if avg_episode_length < 100:
        details.append(
            f"‚ùå Average episode length: {avg_episode_length:.0f} chars (too short: < 100)"
        )
        return 3

    details.append(
        f"‚ö†Ô∏è  Average episode length: {avg_episode_length:.0f} chars (long: > 2000)"
    )
    return 7


def _evaluate_entity_ratio(node_labels: dict[str, int], details: list[str]) -> int:
    """Evaluate entity node ratio and return score."""
    if not node_labels:
        return 0

    entity_count = node_labels.get("Entity", 0)
    total_nodes = sum(node_labels.values())

    if entity_count > 0:
        entity_ratio = entity_count / total_nodes
        if entity_ratio > 0.8:
            details.append(f"‚úÖ Entity node ratio: {entity_ratio:.1%} (good)")
            score = 10
        else:
            details.append(f"‚ö†Ô∏è  Entity node ratio: {entity_ratio:.1%}")
            score = 7
    else:
        score = 0

    details.append(f"   Node label distribution: {node_labels}")
    return score


def _evaluate_fact_diversity(fact_types: dict[str, int], details: list[str]) -> int:
    """Evaluate fact type diversity and return score."""
    unique_fact_types = len(fact_types)

    if unique_fact_types >= 3:
        details.append(f"‚úÖ Fact type count: {unique_fact_types} (diverse)")
        score = 10
    elif unique_fact_types >= 1:
        details.append(f"‚ö†Ô∏è  Fact type count: {unique_fact_types} (low diversity)")
        score = 5
    else:
        details.append("‚ùå No fact types exist")
        score = 0

    if fact_types:
        top_fact_types = sorted(fact_types.items(), key=lambda x: x[1], reverse=True)[
            :5
        ]
        details.append(
            f"   Main fact types: {', '.join([f'{k}({v})' for k, v in top_fact_types])}"
        )

    return score


def calculate_quality_score(stats: dict[str, Any]) -> dict[str, Any]:
    """Calculate overall quality score based on graph statistics."""
    score = 0
    details = []

    episode_count = stats.get("episode_count", 0)
    node_count = stats.get("node_count", 0)
    fact_count = stats.get("fact_count", 0)

    # Evaluate node/episode ratio (10 points)
    score += _evaluate_node_episode_ratio(episode_count, node_count, details)

    # Evaluate fact/node ratio (10 points)
    score += _evaluate_fact_node_ratio(fact_count, node_count, details)

    # Evaluate episode length (10 points)
    avg_episode_length = stats.get("avg_episode_length", 0)
    score += _evaluate_episode_length(avg_episode_length, details)

    # Evaluate entity ratio (10 points)
    node_labels = stats.get("node_labels", {})
    score += _evaluate_entity_ratio(node_labels, details)

    # Evaluate fact diversity (10 points)
    fact_types = stats.get("fact_types", {})
    score += _evaluate_fact_diversity(fact_types, details)

    max_score = 50

    return {
        "score": score,
        "max_score": max_score,
        "percentage": (score / max_score * 100) if max_score > 0 else 0,
        "details": details,
    }


def _print_improvement_suggestions(stats: dict[str, Any]) -> None:
    """Print improvement suggestions based on graph statistics."""
    # Early return patterns - handle critical issues first
    if stats.get("episode_count", 0) == 0:
        print("  - No data has been ingested. Run 'make demo' or ingest data manually")
        return

    if stats.get("node_count", 0) == 0:
        print("  - No nodes generated. Check LLM configuration")
        return

    if stats.get("fact_count", 0) == 0:
        print("  - No relationships extracted. Make episode content more conversational")
        return

    # Provide specific suggestions based on metrics
    _suggest_episode_length_improvements(stats)
    _suggest_node_ratio_improvements(stats)
    _suggest_fact_ratio_improvements(stats)


def _suggest_episode_length_improvements(stats: dict[str, Any]) -> None:
    """Suggest improvements for episode length."""
    avg_length = stats.get("avg_episode_length", 0)

    if avg_length < 100:
        print("  - Episodes too short. Increase time window (e.g., 4H, 1D)")
    elif avg_length > 2000:
        print("  - Episodes too long. Decrease time window (e.g., 30min, 1H)")


def _suggest_node_ratio_improvements(stats: dict[str, Any]) -> None:
    """Suggest improvements for node/episode ratio."""
    node_ratio = stats.get("node_count", 0) / stats.get("episode_count", 1)

    if node_ratio < 0.3:
        print("  - Too few nodes. Create episodes with more specific content")
    elif node_ratio > 3.0:
        print("  - Too many nodes. Make episodes more cohesive")


def _suggest_fact_ratio_improvements(stats: dict[str, Any]) -> None:
    """Suggest improvements for fact/node ratio."""
    fact_ratio = stats.get("fact_count", 0) / max(stats.get("node_count", 1), 1)

    if fact_ratio < 0.5:
        print("  - Too few relationships. Recommend thread-based chunking")


async def validate_graph(verbose: bool = False) -> None:
    async with streamablehttp_client("http://localhost:8001/mcp/") as (read, write, _):
        async with ClientSession(read, write) as session:
            await session.initialize()

            print("=" * 70)
            print("Graphiti Knowledge Graph Quality Validation")
            print("=" * 70)

            stats = await get_graph_statistics(session)

            print("\nüìä Basic Statistics:")
            print(f"  Episode count: {stats.get('episode_count', 0)}")
            print(f"  Node count: {stats.get('node_count', 0)}")
            print(f"  Fact count: {stats.get('fact_count', 0)}")

            if verbose:
                print("\nüìè Detailed Statistics:")
                if "avg_episode_length" in stats:
                    print(f"  Average episode length: {stats['avg_episode_length']:.0f} chars")
                    print(
                        f"  Min episode length: {stats.get('min_episode_length', 0)} chars"
                    )
                    print(
                        f"  Max episode length: {stats.get('max_episode_length', 0)} chars"
                    )
                if "avg_node_summary_length" in stats:
                    print(
                        f"  Average node summary length: {stats['avg_node_summary_length']:.0f} chars"
                    )

            quality = calculate_quality_score(stats)

            print("\nüéØ Quality Score:")
            print(
                f"  {quality['score']}/{quality['max_score']} ({quality['percentage']:.1f}%)"
            )

            print("\nüìã Evaluation Details:")
            for detail in quality["details"]:
                print(f"  {detail}")

            print("\nüí° Overall Evaluation:")
            percentage = quality["percentage"]
            if percentage >= 80:
                print("  ‚úÖ Excellent - Graph is high quality")
            elif percentage >= 60:
                print("  ‚ö†Ô∏è  Good - Some room for improvement")
            elif percentage >= 40:
                print("  ‚ö†Ô∏è  Needs Improvement - Recommend reviewing chunking strategy")
            else:
                print("  ‚ùå Poor - Issues with data ingestion or chunking")

            print("\nüìù Improvement Suggestions:")
            _print_improvement_suggestions(stats)
            print("\n" + "=" * 70)


async def main():
    parser = argparse.ArgumentParser(
        description="Validate Graphiti knowledge graph quality."
    )
    parser.add_argument(
        "-v", "--verbose", action="store_true", help="Display detailed statistics."
    )
    args = parser.parse_args()

    await validate_graph(verbose=args.verbose)


if __name__ == "__main__":
    asyncio.run(main())
