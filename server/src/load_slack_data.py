import argparse
import asyncio
from datetime import datetime, timezone

import pandas as pd
from mcp import ClientSession
from mcp.client.streamable_http import streamablehttp_client  # HTTP æ¥ç¶šç”¨
from tqdm import tqdm


def chunk_slack_data(threads_df: pd.DataFrame, time_window: str = "1h") -> list[dict]:
    chunks = []

    # ãƒ‘ã‚¿ãƒ¼ãƒ³1: ã‚¹ãƒ¬ãƒƒãƒ‰å˜ä½ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    # reply_count > 0 ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰ã®è¦ªï¼‰ã¨ãã®è¿”ä¿¡ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    # thread_tsåˆ—ã‚’ä½¿ã£ã¦ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’è­˜åˆ¥ã™ã‚‹
    has_thread = threads_df["thread_ts"].notna() & (
        threads_df["thread_ts"].astype(str) != "nan"
    )

    # ã‚¹ãƒ¬ãƒƒãƒ‰ã«å±ã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆè¦ª or å­ï¼‰
    threaded_messages = threads_df[has_thread].copy()

    if not threaded_messages.empty:
        # thread_tsã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆè¦ªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãã®è¿”ä¿¡ãŒåŒã˜thread_tsã‚’æŒã¤ï¼‰
        for thread_ts, group in threaded_messages.groupby("thread_ts"):
            sorted_msgs = group.sort_values("ts")

            conversation_lines = []
            for _, row in sorted_msgs.iterrows():
                user = str(row["user_display"])
                content = str(row["content"])
                conversation_lines.append(f"{user}: {content}")

            conversation = "\n".join(conversation_lines)

            first_msg = sorted_msgs.iloc[0]
            chunks.append(
                {
                    "name": f"Thread_{str(thread_ts)[:8]}",
                    "body": conversation,
                    "timestamp_str": str(first_msg["ts"]),
                    "type": "thread",
                    "thread_ts": str(thread_ts),
                    "message_count": len(sorted_msgs),
                }
            )

    # ãƒ‘ã‚¿ãƒ¼ãƒ³2: ã‚¹ãƒ¬ãƒƒãƒ‰ã®ãªã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆis_parent=True ã‹ã¤ reply_count=0ï¼‰ã‚’æ™‚é–“çª“ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    # thread_tsãŒãªã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
    non_thread_mask = threads_df["thread_ts"].isna() | (
        threads_df["thread_ts"].astype(str) == "nan"
    )
    non_threaded = threads_df[non_thread_mask].copy()

    if not non_threaded.empty:
        non_threaded["ts_datetime"] = pd.to_datetime(
            non_threaded["ts"], errors="coerce", utc=True
        )
        non_threaded = non_threaded.dropna(subset=["ts_datetime"])

        non_threaded["time_window"] = non_threaded["ts_datetime"].dt.floor(time_window)

        for window, group in non_threaded.groupby("time_window"):
            sorted_msgs = group.sort_values("ts")

            conversation_lines = []
            for _, row in sorted_msgs.iterrows():
                user = str(row["user_display"])
                content = str(row["content"])
                conversation_lines.append(f"{user}: {content}")

            conversation = "\n".join(conversation_lines)

            first_msg = sorted_msgs.iloc[0]
            window_str = window.strftime("%Y%m%d_%H%M")
            chunks.append(
                {
                    "name": f"Chat_{window_str}",
                    "body": conversation,
                    "timestamp_str": str(first_msg["ts"]),
                    "type": "time_window",
                    "window": window_str,
                    "message_count": len(sorted_msgs),
                }
            )

    return chunks


async def add_slack_data(
    session: ClientSession, time_window: str = "1h", chunked: bool = True
) -> None:
    import os
    from pathlib import Path

    script_dir = Path(__file__).parent.parent

    # Use English CSV by default if available, fallback to original
    threads_en_path = script_dir / "slack_data" / "threads_ordered_en.csv"
    threads_path = (
        threads_en_path
        if threads_en_path.exists()
        else script_dir / "slack_data" / "threads_ordered.csv"
    )

    slack_data_paths = {
        "threads": threads_path,
        "users": script_dir / "slack_data" / "users_used.csv",
    }

    threads_df = pd.read_csv(slack_data_paths["threads"])
    users_df = pd.read_csv(slack_data_paths["users"])

    print(f"  ğŸ’¬ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(threads_df)}")
    print(f"  ğŸ‘¥ ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°: {len(users_df)}")

    if chunked:
        print(f"  ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯åŒ–ãƒ¢ãƒ¼ãƒ‰: æœ‰åŠ¹ï¼ˆæ™‚é–“çª“={time_window}ï¼‰")
        chunks = chunk_slack_data(threads_df, time_window)
        print(f"  ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯æ•°: {len(chunks)}")

        thread_chunks = [c for c in chunks if c["type"] == "thread"]
        time_chunks = [c for c in chunks if c["type"] == "time_window"]
        print(f"    - ã‚¹ãƒ¬ãƒƒãƒ‰ãƒãƒ£ãƒ³ã‚¯: {len(thread_chunks)}")
        print(f"    - æ™‚é–“çª“ãƒãƒ£ãƒ³ã‚¯: {len(time_chunks)}")

        for chunk in tqdm(chunks, desc="ãƒãƒ£ãƒ³ã‚¯ã‚’æŠ•å…¥ä¸­"):
            timestamp_str = chunk["timestamp_str"]

            try:
                message_time = datetime.fromisoformat(
                    timestamp_str.replace("Z", "+00:00")
                )
            except ValueError:
                try:
                    timestamp_float = float(timestamp_str)
                    message_time = datetime.fromtimestamp(
                        timestamp_float, tz=timezone.utc
                    )
                except (ValueError, TypeError):
                    print(f"âš ï¸  ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è§£æã‚¨ãƒ©ãƒ¼: {timestamp_str}")
                    continue

            metadata_str = f"timestamp: {message_time.isoformat()}, chunk_type: {chunk['type']}, message_count: {chunk['message_count']}"
            if chunk["type"] == "thread":
                metadata_str += f", thread_ts: {chunk['thread_ts']}"
            else:
                metadata_str += f", time_window: {chunk['window']}"

            arguments = {
                "name": chunk["name"],
                "episode_body": chunk["body"],
                "source": "message",
                "source_description": metadata_str,
            }

            await session.call_tool("add_memory", arguments=arguments)
    else:
        print("  ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯åŒ–ãƒ¢ãƒ¼ãƒ‰: ç„¡åŠ¹ï¼ˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å˜ä½ã§æŠ•å…¥ï¼‰")
        for _, row in tqdm(threads_df.iterrows(), total=len(threads_df)):
            message_id = str(row["message_id"])
            user_display = str(row["user_display"])
            content = str(row["content"])
            timestamp_str = str(row["ts"])

            try:
                thread_ts = (
                    str(row["thread_ts"]) if str(row["thread_ts"]) != "nan" else None
                )
            except Exception:
                thread_ts = None

            try:
                is_parent = bool(row["is_parent"])
            except Exception:
                is_parent = False

            try:
                message_time = datetime.fromisoformat(
                    timestamp_str.replace("Z", "+00:00")
                )
            except ValueError:
                try:
                    timestamp_float = float(timestamp_str)
                    message_time = datetime.fromtimestamp(
                        timestamp_float, tz=timezone.utc
                    )
                except (ValueError, TypeError):
                    print(
                        f"âš ï¸  ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è§£æã‚¨ãƒ©ãƒ¼ ({message_id}): {timestamp_str}"
                    )
                    continue

            episode_name = f"Slack_{message_id[:8]}"
            if is_parent:
                episode_name += "_thread"

            episode_content = f"{user_display}: {content}"

            if not is_parent and thread_ts:
                episode_content += f"\n[è¿”ä¿¡: ã‚¹ãƒ¬ãƒƒãƒ‰ {thread_ts}]"

            metadata_str = f"timestamp: {message_time.isoformat()}, message_id: {message_id}, user: {user_display}, thread_ts: {thread_ts}, is_parent: {is_parent}"

            arguments = {
                "name": episode_name,
                "episode_body": episode_content,
                "source": "message",
                "source_description": metadata_str,
            }
            await session.call_tool("add_memory", arguments=arguments)


async def main():
    parser = argparse.ArgumentParser(
        description="Slackãƒ‡ãƒ¼ã‚¿ã‚’Graphitiã«æŠ•å…¥ã—ã¾ã™ã€‚ãƒãƒ£ãƒ³ã‚¯åŒ–ã«ã‚ˆã‚Šé–¢é€£ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã§ãã¾ã™ã€‚"
    )
    parser.add_argument(
        "--clear_existing",
        action="store_true",
        help="æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‹ã‚‰Slackãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¾ã™ã€‚",
    )
    parser.add_argument(
        "--no-chunk",
        action="store_true",
        help="ãƒãƒ£ãƒ³ã‚¯åŒ–ã‚’ç„¡åŠ¹ã«ã—ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å˜ä½ã§æŠ•å…¥ã—ã¾ã™ã€‚",
    )
    parser.add_argument(
        "--time-window",
        type=str,
        default="1h",
        help="ã‚¹ãƒ¬ãƒƒãƒ‰ã®ãªã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹æ™‚é–“çª“ï¼ˆä¾‹: 1h, 2h, 1dï¼‰ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯1hï¼ˆ1æ™‚é–“ï¼‰ã€‚",
    )
    args = parser.parse_args()

    async with streamablehttp_client("http://localhost:8001/mcp/") as (read, write, _):
        async with ClientSession(read, write) as session:
            await session.initialize()
            if args.clear_existing:
                print("æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã„ã¾ã™...")
                await session.call_tool("clear_graph", arguments={})
            await add_slack_data(
                session, time_window=args.time_window, chunked=not args.no_chunk
            )


if __name__ == "__main__":
    asyncio.run(main())
